#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Process Service Implementation using Connect RPC
"""

import asyncio
import os
import signal as sig
import subprocess
from typing import Dict, Optional

import psutil

from shared.logger import setup_logger

# Will be generated by generate.sh
try:
    from ..gen.process.process import process_pb2
except ImportError:
    process_pb2 = None

logger = setup_logger("process_service")


class ConnectError(Exception):
    """Connect RPC error"""

    def __init__(self, code: str, message: str):
        self.code = code
        self.message = message
        super().__init__(message)


class ProcessManager:
    """Manages running processes"""

    def __init__(self):
        self.processes: Dict[int, subprocess.Popen] = {}
        self.tagged_processes: Dict[str, int] = {}  # tag -> pid mapping
        self.pty_fds: Dict[int, int] = {}  # pid -> master fd mapping for PTY processes

    def add_process(
        self,
        pid: int,
        process: subprocess.Popen,
        tag: Optional[str] = None,
        pty_fd: Optional[int] = None,
    ):
        """Add a process to the manager"""
        self.processes[pid] = process
        if tag:
            self.tagged_processes[tag] = pid
        if pty_fd is not None:
            self.pty_fds[pid] = pty_fd

    def get_pty_fd(self, selector: process_pb2.ProcessSelector) -> Optional[int]:
        """Get PTY master fd for a process"""
        pid = self.get_pid(selector)
        if pid:
            return self.pty_fds.get(pid)
        return None

    def get_process(
        self, selector: process_pb2.ProcessSelector
    ) -> Optional[subprocess.Popen]:
        """Get a process by selector (pid or tag)"""
        if selector.HasField("pid"):
            return self.processes.get(selector.pid)
        elif selector.HasField("tag"):
            pid = self.tagged_processes.get(selector.tag)
            if pid:
                return self.processes.get(pid)
        return None

    def get_pid(self, selector: process_pb2.ProcessSelector) -> Optional[int]:
        """Get PID from selector"""
        if selector.HasField("pid"):
            return selector.pid
        elif selector.HasField("tag"):
            return self.tagged_processes.get(selector.tag)
        return None

    def list_processes(self):
        """List all managed processes"""
        return [
            (pid, proc, tag if tag and self.tagged_processes.get(tag) == pid else None)
            for pid, proc in self.processes.items()
            for tag in [None] + list(self.tagged_processes.keys())
        ]

    def remove_process(self, pid: int):
        """Remove a process from the manager"""
        if pid in self.processes:
            del self.processes[pid]
        # Remove from tagged_processes
        tags_to_remove = [tag for tag, p in self.tagged_processes.items() if p == pid]
        for tag in tags_to_remove:
            del self.tagged_processes[tag]
        # Remove PTY fd if exists
        if pid in self.pty_fds:
            del self.pty_fds[pid]


class ProcessServiceHandler:
    """Handler for Process service RPC methods"""

    def __init__(self):
        self.manager = ProcessManager()

    async def List(self, request: process_pb2.ListRequest) -> process_pb2.ListResponse:
        """List all running processes in the system"""
        logger.debug("List request received")

        processes = []

        try:
            # Iterate through all system processes
            for proc in psutil.process_iter(["pid", "name", "cmdline", "username"]):
                try:
                    pinfo = proc.info
                    pid = pinfo["pid"]
                    cmdline = pinfo.get("cmdline") or []

                    # Skip kernel processes with no cmdline
                    if not cmdline:
                        continue

                    # Build ProcessConfig
                    cmd = cmdline[0] if cmdline else ""
                    args = cmdline[1:] if len(cmdline) > 1 else []

                    # Check if this process was started by our manager
                    tag = None
                    for t, managed_pid in self.manager.tagged_processes.items():
                        if managed_pid == pid:
                            tag = t
                            break

                    info = process_pb2.ProcessInfo(
                        pid=pid,
                        config=process_pb2.ProcessConfig(
                            cmd=cmd,
                            args=args,
                        ),
                    )

                    if tag:
                        info.tag = tag

                    processes.append(info)

                except (
                    psutil.NoSuchProcess,
                    psutil.AccessDenied,
                    psutil.ZombieProcess,
                ):
                    # Skip processes that disappeared or we don't have access to
                    continue

        except Exception as e:
            logger.warning(f"Error listing processes: {e}")

        return process_pb2.ListResponse(processes=processes)

    async def Start(self, request: process_pb2.StartRequest):
        """Start a new process and stream its output"""
        logger.info(
            f"Starting process: {request.process.cmd} {list(request.process.args)}"
        )

        try:
            # Prepare environment
            env = os.environ.copy()
            if request.process.envs:
                env.update(request.process.envs)

            # Prepare command
            cmd = [request.process.cmd] + list(request.process.args)

            # Determine working directory
            cwd = request.process.cwd if request.process.cwd else None

            # Start process
            if request.HasField("pty"):
                # PTY mode - use pty
                import pty

                master, slave = pty.openpty()

                proc = subprocess.Popen(
                    cmd,
                    stdin=slave if request.stdin else subprocess.DEVNULL,
                    stdout=slave,
                    stderr=slave,
                    env=env,
                    cwd=cwd,
                    preexec_fn=os.setsid,
                )
                os.close(slave)

                # Store process with PTY master fd
                self.manager.add_process(
                    proc.pid,
                    proc,
                    request.tag if request.HasField("tag") else None,
                    pty_fd=master,
                )

                # Send start event
                yield process_pb2.StartResponse(
                    event=process_pb2.ProcessEvent(
                        start=process_pb2.ProcessEvent.StartEvent(pid=proc.pid)
                    )
                )

                # Create tasks for reading PTY and sending keepalive
                loop = asyncio.get_event_loop()
                process_running = True
                last_data_time = loop.time()
                keepalive_interval = 5.0  # 5 seconds

                async def read_pty_output():
                    nonlocal process_running, last_data_time
                    import fcntl
                    import select

                    # Set master fd to non-blocking
                    flags = fcntl.fcntl(master, fcntl.F_GETFL)
                    fcntl.fcntl(master, fcntl.F_SETFL, flags | os.O_NONBLOCK)

                    while proc.poll() is None:
                        try:
                            # Use select to check if data is available with timeout
                            ready, _, _ = await loop.run_in_executor(
                                None, select.select, [master], [], [], 0.5
                            )
                            if ready:
                                try:
                                    data = os.read(master, 4096)
                                    if data:
                                        last_data_time = loop.time()
                                        yield process_pb2.StartResponse(
                                            event=process_pb2.ProcessEvent(
                                                data=process_pb2.ProcessEvent.DataEvent(
                                                    pty=data
                                                )
                                            )
                                        )
                                except (OSError, BlockingIOError):
                                    # No data available or fd closed
                                    pass
                            else:
                                # Timeout, yield control
                                await asyncio.sleep(0.1)
                        except (OSError, ValueError):
                            # FD closed or invalid
                            break
                    process_running = False

                async def send_keepalive():
                    while process_running:
                        await asyncio.sleep(keepalive_interval)
                        # Only send keepalive if no data was sent recently and process still running
                        if (
                            process_running
                            and loop.time() - last_data_time >= keepalive_interval
                        ):
                            yield process_pb2.StartResponse(
                                event=process_pb2.ProcessEvent(
                                    keepalive=process_pb2.ProcessEvent.KeepAlive()
                                )
                            )

                # Merge streams from PTY output and keepalive
                try:
                    async for response in self._merge_async_generators(
                        [read_pty_output(), send_keepalive()]
                    ):
                        yield response
                except Exception as e:
                    logger.exception(f"Error in PTY stream: {e}")
                # Note: Don't close master fd here - it's needed for SendInput/Update
                # It will be closed in cleanup when process exits

            else:
                # Normal mode - separate stdout/stderr
                proc = subprocess.Popen(
                    cmd,
                    stdin=subprocess.PIPE if request.stdin else subprocess.DEVNULL,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    env=env,
                    cwd=cwd,
                )

                # Store process
                self.manager.add_process(
                    proc.pid, proc, request.tag if request.HasField("tag") else None
                )

                # Send start event
                yield process_pb2.StartResponse(
                    event=process_pb2.ProcessEvent(
                        start=process_pb2.ProcessEvent.StartEvent(pid=proc.pid)
                    )
                )

                # Track data events for keepalive timing
                loop = asyncio.get_event_loop()
                last_data_time = loop.time()
                keepalive_interval = 5.0
                process_running = True

                # Stream output
                async def read_stream(stream, is_stderr=False):
                    nonlocal last_data_time
                    while True:
                        try:
                            data = await loop.run_in_executor(None, stream.read, 4096)
                            if not data:
                                break
                            last_data_time = loop.time()
                            if is_stderr:
                                yield process_pb2.ProcessEvent.DataEvent(stderr=data)
                            else:
                                yield process_pb2.ProcessEvent.DataEvent(stdout=data)
                        except Exception as e:
                            logger.warning(f"Error reading stream: {e}")
                            break

                async def send_keepalive():
                    nonlocal process_running
                    while process_running and proc.poll() is None:
                        await asyncio.sleep(keepalive_interval)
                        # Only send keepalive if no data was sent recently and process still running
                        if (
                            process_running
                            and proc.poll() is None
                            and loop.time() - last_data_time >= keepalive_interval
                        ):
                            yield process_pb2.StartResponse(
                                event=process_pb2.ProcessEvent(
                                    keepalive=process_pb2.ProcessEvent.KeepAlive()
                                )
                            )

                # Read both streams concurrently
                tasks = []
                if proc.stdout:
                    tasks.append(read_stream(proc.stdout, False))
                if proc.stderr:
                    tasks.append(read_stream(proc.stderr, True))

                async def data_stream():
                    if tasks:
                        async for data_event in self._merge_streams(tasks):
                            yield process_pb2.StartResponse(
                                event=process_pb2.ProcessEvent(data=data_event)
                            )

                # Merge data stream and keepalive
                try:
                    async for response in self._merge_async_generators(
                        [data_stream(), send_keepalive()]
                    ):
                        yield response
                except Exception as e:
                    logger.exception(f"Error in stream merge: {e}")
                finally:
                    process_running = False

            # Wait for process to complete (non-blocking check)
            returncode = proc.poll()
            if returncode is None:
                # Process still running, wait asynchronously
                returncode = await loop.run_in_executor(None, proc.wait)

            # Send end event
            yield process_pb2.StartResponse(
                event=process_pb2.ProcessEvent(
                    end=process_pb2.ProcessEvent.EndEvent(
                        exit_code=returncode,
                        exited=True,
                        status="completed",
                    )
                )
            )

            # Clean up - process will be removed by background cleanup
            # The manager will handle cleanup when process exits

        except Exception as e:
            logger.exception(f"Error starting process: {e}")
            yield process_pb2.StartResponse(
                event=process_pb2.ProcessEvent(
                    end=process_pb2.ProcessEvent.EndEvent(
                        exit_code=-1,
                        exited=False,
                        status="failed",
                        error=str(e),
                    )
                )
            )
        finally:
            # Background cleanup - only remove from manager if process has exited
            if "proc" in locals():
                asyncio.create_task(self._cleanup_finished_process(proc.pid))

    async def Connect(self, request: process_pb2.ConnectRequest):
        """Connect to an existing process and monitor its status"""
        logger.info(f"Connect request for process selector: {request.process}")

        # Try to get process from manager first (for processes started via Start)
        proc = self.manager.get_process(request.process)
        pid = self.manager.get_pid(request.process)

        # If not in manager, try to get from system by PID
        if not pid and request.process.HasField("pid"):
            pid = request.process.pid
            try:
                # Verify the process exists in the system
                psutil.Process(pid)
                proc = None  # System process, not managed by us
            except psutil.NoSuchProcess:
                raise ConnectError(
                    code="not_found",
                    message=f"Process with PID {pid} not found",
                )
        elif not pid:
            raise ConnectError(
                code="not_found",
                message="Process not found",
            )

        # Send start event with PID
        yield process_pb2.ConnectResponse(
            event=process_pb2.ProcessEvent(
                start=process_pb2.ProcessEvent.StartEvent(pid=pid)
            )
        )

        # Monitor process status
        try:
            if proc:
                # Managed process - use subprocess.Popen
                # Check if already finished
                if proc.poll() is not None:
                    yield process_pb2.ConnectResponse(
                        event=process_pb2.ProcessEvent(
                            end=process_pb2.ProcessEvent.EndEvent(
                                exit_code=proc.returncode,
                                exited=True,
                                status="completed",
                            )
                        )
                    )
                    return

                # Send keepalive while running
                while proc.poll() is None:
                    yield process_pb2.ConnectResponse(
                        event=process_pb2.ProcessEvent(
                            keepalive=process_pb2.ProcessEvent.KeepAlive()
                        )
                    )
                    await asyncio.sleep(5)

                # Send end event
                yield process_pb2.ConnectResponse(
                    event=process_pb2.ProcessEvent(
                        end=process_pb2.ProcessEvent.EndEvent(
                            exit_code=proc.returncode,
                            exited=True,
                            status="completed",
                        )
                    )
                )
            else:
                # System process - use psutil
                try:
                    ps_proc = psutil.Process(pid)

                    # Monitor while process is running
                    while ps_proc.is_running():
                        yield process_pb2.ConnectResponse(
                            event=process_pb2.ProcessEvent(
                                keepalive=process_pb2.ProcessEvent.KeepAlive()
                            )
                        )
                        await asyncio.sleep(5)

                        # Refresh process info
                        try:
                            ps_proc.status()
                        except psutil.NoSuchProcess:
                            break

                    # Process ended
                    yield process_pb2.ConnectResponse(
                        event=process_pb2.ProcessEvent(
                            end=process_pb2.ProcessEvent.EndEvent(
                                exit_code=-1,  # Unknown exit code for system processes
                                exited=True,
                                status="completed",
                            )
                        )
                    )
                except psutil.NoSuchProcess:
                    # Process already finished
                    yield process_pb2.ConnectResponse(
                        event=process_pb2.ProcessEvent(
                            end=process_pb2.ProcessEvent.EndEvent(
                                exit_code=-1,
                                exited=True,
                                status="completed",
                            )
                        )
                    )
        except Exception as e:
            logger.exception(f"Error in Connect: {e}")
            yield process_pb2.ConnectResponse(
                event=process_pb2.ProcessEvent(
                    end=process_pb2.ProcessEvent.EndEvent(
                        exit_code=-1,
                        exited=False,
                        status="failed",
                        error=str(e),
                    )
                )
            )

    async def Update(
        self, request: process_pb2.UpdateRequest
    ) -> process_pb2.UpdateResponse:
        """Update process settings (e.g., PTY size)"""
        logger.info(f"Update request for process selector: {request.process}")

        proc = self.manager.get_process(request.process)
        if not proc:
            raise ConnectError(
                code="not_found",
                message="Process not found",
            )

        # Update PTY size if provided
        if request.HasField("pty"):
            pty_fd = self.manager.get_pty_fd(request.process)
            if pty_fd is None:
                raise ConnectError(
                    code="invalid_argument",
                    message="Process is not running in PTY mode",
                )

            try:
                import fcntl
                import struct
                import termios

                rows = request.pty.size.rows
                cols = request.pty.size.cols

                # Pack window size: rows, cols, x pixels, y pixels
                winsize = struct.pack("HHHH", rows, cols, 0, 0)
                fcntl.ioctl(pty_fd, termios.TIOCSWINSZ, winsize)

                logger.debug(f"Resized PTY for PID {proc.pid} to {rows}x{cols}")
            except Exception as e:
                logger.exception(f"Error resizing PTY: {e}")
                raise ConnectError(
                    code="internal",
                    message=f"Failed to resize TTY: {str(e)}",
                )

        return process_pb2.UpdateResponse()

    def _handle_input(
        self,
        process_selector: process_pb2.ProcessSelector,
        input_data: process_pb2.ProcessInput,
    ):
        """Shared helper to handle input for both SendInput and StreamInput"""
        proc = self.manager.get_process(process_selector)
        if not proc:
            raise ConnectError(
                code="not_found",
                message="Process not found",
            )

        # Handle stdin input
        if input_data.HasField("stdin"):
            if not proc.stdin:
                raise ConnectError(
                    code="failed_precondition",
                    message="Process stdin not available",
                )
            try:
                proc.stdin.write(input_data.stdin)
                proc.stdin.flush()
            except Exception as e:
                logger.exception(f"Error writing to stdin: {e}")
                raise ConnectError(
                    code="internal",
                    message=f"Failed to write to stdin: {str(e)}",
                )

        # Handle PTY input
        elif input_data.HasField("pty"):
            pty_fd = self.manager.get_pty_fd(process_selector)
            if pty_fd is None:
                raise ConnectError(
                    code="failed_precondition",
                    message="Process is not running in PTY mode",
                )
            try:
                os.write(pty_fd, input_data.pty)
            except Exception as e:
                logger.exception(f"Error writing to PTY: {e}")
                raise ConnectError(
                    code="internal",
                    message=f"Failed to write to PTY: {str(e)}",
                )

    async def SendInput(
        self, request: process_pb2.SendInputRequest
    ) -> process_pb2.SendInputResponse:
        """Send input to a process"""
        logger.debug(f"SendInput request for process selector: {request.process}")

        self._handle_input(request.process, request.input)
        return process_pb2.SendInputResponse()

    async def StreamInput(self, request_iterator) -> process_pb2.StreamInputResponse:
        """Stream input to a process"""
        logger.info("StreamInput request received")

        process_selector = None
        async for request in request_iterator:
            if request.HasField("start"):
                # Initialize process connection
                process_selector = request.start.process
                # Verify process exists
                proc = self.manager.get_process(process_selector)
                if not proc:
                    raise ConnectError(
                        code="not_found",
                        message="Process not found",
                    )
            elif request.HasField("data"):
                if not process_selector:
                    raise ConnectError(
                        code="failed_precondition",
                        message="Process not started",
                    )
                # Handle input using shared helper
                self._handle_input(process_selector, request.data.input)
            elif request.HasField("keepalive"):
                # Just keep connection alive
                pass

        return process_pb2.StreamInputResponse()

    async def SendSignal(
        self, request: process_pb2.SendSignalRequest
    ) -> process_pb2.SendSignalResponse:
        """Send a signal to a process"""
        logger.info(
            f"SendSignal request for process selector: {request.process}, signal: {request.signal}"
        )

        # Get process
        proc = self.manager.get_process(request.process)
        if not proc:
            raise ConnectError(
                code="not_found",
                message="Process not found",
            )

        # Map proto signal to OS signal
        if request.signal == process_pb2.SIGNAL_SIGKILL:
            os_signal = sig.SIGKILL
        elif request.signal == process_pb2.SIGNAL_SIGTERM:
            os_signal = sig.SIGTERM
        else:
            raise ConnectError(
                code="invalid_argument",
                message=f"Invalid signal: {request.signal}",
            )

        # Send signal to process
        try:
            proc.send_signal(os_signal)
            logger.debug(f"Successfully sent signal {os_signal} to PID {proc.pid}")
        except Exception as e:
            logger.exception(f"Error sending signal to process: {e}")
            raise ConnectError(
                code="internal",
                message=f"Error sending signal: {str(e)}",
            )

        return process_pb2.SendSignalResponse()

    async def _merge_streams(self, generators):
        """Merge multiple async generators"""
        tasks = {}
        for gen in generators:
            try:
                task = asyncio.create_task(self._safe_anext(gen))
                tasks[task] = gen
            except Exception as e:
                logger.warning(f"Error creating task in merge_streams: {e}")

        while tasks:
            if not tasks:
                break

            done, _ = await asyncio.wait(
                tasks.keys(), return_when=asyncio.FIRST_COMPLETED
            )

            for task in done:
                gen = tasks.pop(task)
                try:
                    result = await task
                    if result is not None:
                        yield result
                        # Re-add task for next iteration
                        try:
                            new_task = asyncio.create_task(self._safe_anext(gen))
                            tasks[new_task] = gen
                        except Exception as e:
                            logger.warning(f"Error re-adding task: {e}")
                except StopAsyncIteration:
                    # Generator exhausted
                    pass
                except Exception as e:
                    # Log unexpected errors but continue
                    logger.warning(f"Error in merge_streams: {e}")

    async def _merge_async_generators(self, generators):
        """Merge multiple async generators that yield complete responses"""
        tasks = {}
        for gen in generators:
            try:
                task = asyncio.create_task(self._safe_anext(gen))
                tasks[task] = gen
            except Exception as e:
                logger.warning(f"Error creating task in merge_async_generators: {e}")

        while tasks:
            if not tasks:
                break

            done, _ = await asyncio.wait(
                tasks.keys(), return_when=asyncio.FIRST_COMPLETED
            )

            for task in done:
                gen = tasks.pop(task)
                try:
                    result = await task
                    if result is not None:
                        yield result
                        # Re-add task for next iteration
                        try:
                            new_task = asyncio.create_task(self._safe_anext(gen))
                            tasks[new_task] = gen
                        except Exception as e:
                            logger.warning(f"Error re-adding task: {e}")
                except StopAsyncIteration:
                    # Generator exhausted
                    pass
                except Exception as e:
                    # Log unexpected errors but continue
                    logger.warning(f"Error in merge_async_generators: {e}")

    async def _safe_anext(self, gen):
        """Safely get next item from async generator, catching StopAsyncIteration"""
        try:
            return await gen.__anext__()
        except StopAsyncIteration:
            # Signal that generator is exhausted by returning None
            return None

    async def _cleanup_process(self, pid: int):
        """Background cleanup of finished process"""
        await asyncio.sleep(1)  # Give process time to finish
        try:
            self.manager.remove_process(pid)
            logger.debug(f"Cleaned up process {pid}")
        except Exception as e:
            logger.warning(f"Error cleaning up process {pid}: {e}")

    async def _cleanup_finished_process(self, pid: int):
        """Cleanup process from manager only if it has exited"""
        try:
            # Check if process is in manager
            proc = None
            for p, process_obj in self.manager.processes.items():
                if p == pid:
                    proc = process_obj
                    break

            if not proc:
                # Not a managed process, nothing to clean up
                return

            # Wait for process to exit (with timeout)
            loop = asyncio.get_event_loop()
            max_wait = 300  # 5 minutes max
            start_time = loop.time()

            while proc.poll() is None:
                await asyncio.sleep(1)
                if loop.time() - start_time > max_wait:
                    logger.warning(
                        f"Process {pid} did not exit after {max_wait}s, removing from manager anyway"
                    )
                    break

            # Close PTY master fd if exists
            pty_fd = self.manager.pty_fds.get(pid)
            if pty_fd is not None:
                try:
                    os.close(pty_fd)
                    logger.debug(f"Closed PTY fd {pty_fd} for process {pid}")
                except OSError as e:
                    logger.warning(f"Error closing PTY fd for process {pid}: {e}")

            # Process has exited or timed out, remove from manager
            self.manager.remove_process(pid)
            logger.debug(f"Cleaned up finished process {pid}")
        except Exception as e:
            logger.warning(f"Error cleaning up process {pid}: {e}")
